{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2ee366-d010-4d2c-b140-293bbd1d1364",
   "metadata": {},
   "source": [
    "# Quality Control for Ecological Data using the Frictionless Framework\n",
    "\n",
    "### 1. **Introduction to Frictionless**\n",
    "\n",
    "The **Frictionless framework** is a set of open-source tools for managing and ensuring data quality. It helps with the validation, cleaning, and documentation of datasets. Researchers and IT staff can use it to ensure the ecological data uploaded to EnviDat meets specific quality standards.\n",
    "\n",
    "* **For Researchers (Self-check)**: Use the graphical interface ([Open Data Editor](https://okfn.org/en/projects/open-data-editor/)) to validate datasets before upload.\n",
    "* **For IT Staff (Backend Check)**: Automate quality control through Python scripts that validate data on upload.\n",
    "\n",
    "You can explore the detailed documentation:\n",
    "\n",
    "* [Frictionless Framework Documentation](https://framework.frictionlessdata.io/index.html)\n",
    "* [Frictionless RDM Workflows (Colab Example)](https://colab.research.google.com/github/frictionlessdata/frictionless-py/blob/v4/site/docs/tutorials/notebooks/frictionless-RDM-workflows.ipynb#scrollTo=dc538394)\n",
    "\n",
    "### 2. **Setting Up the Environment**\n",
    "\n",
    "# Let's install the frictionless package if it's not already installed.\n",
    "```python\n",
    "!pip install frictionless\n",
    "```\n",
    "First, we will load the sample ecological dataset and explore it.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Sample data provided by WSL for ecological measurements\n",
    "data = \"\"\"\n",
    "Site.ID,Biomasstype,Site,Invasion,Treatment,Weight_20by100_cm\n",
    "1,Litter,PnK,Native,Open,15.515\n",
    "1,Living,PnK,Native,Open,95.89\n",
    "2,Litter,PnK,Native,No livestock,39.14\n",
    "2,Living,PnK,Native,No livestock,177.355\n",
    "3,Litter,PnK,Native,No mammals,38.95\n",
    "3,Living,PnK,Native,No mammals,117.16\n",
    "...\n",
    "48,Living,David,Invaded,No insects,150.84\n",
    "\"\"\"\n",
    "\n",
    "# Convert the data into a pandas dataframe\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.head()\n",
    "```\n",
    "\n",
    "### 3. **Defining a Schema for Data Validation**\n",
    "\n",
    "To validate the dataset, we need to define the expected structure and rules for each column. We will use the **Frictionless** schema to define field types and constraints.\n",
    "\n",
    "```python\n",
    "from frictionless import Schema, Field\n",
    "\n",
    "# Define the schema for the ecological dataset\n",
    "schema = Schema(fields=[\n",
    "    Field(name=\"Site.ID\", type=\"integer\", required=True),\n",
    "    Field(name=\"Biomasstype\", type=\"string\", allowed=[\"Living\", \"Litter\"], required=True),\n",
    "    Field(name=\"Site\", type=\"string\", required=True),\n",
    "    Field(name=\"Invasion\", type=\"string\", allowed=[\"Native\", \"Invaded\"], required=True),\n",
    "    Field(name=\"Treatment\", type=\"string\", allowed=[\"Open\", \"No livestock\", \"No mammals\", \"No insects\"], required=True),\n",
    "    Field(name=\"Weight_20by100_cm\", type=\"number\", required=True)\n",
    "])\n",
    "\n",
    "# Validate the dataset against the schema\n",
    "report = schema.validate(df)\n",
    "\n",
    "# Display the validation issues (if any)\n",
    "report.to_dict()\n",
    "```\n",
    "\n",
    "### 4. **Identifying Common Data Issues**\n",
    "\n",
    "Next, we will check for two common data issues in ecological datasets:\n",
    "\n",
    "1. **Missing values** in critical columns like `Weight_20by100_cm`.\n",
    "2. **Outliers** in numerical data, such as extreme weight values that may be erroneous.\n",
    "\n",
    "```python\n",
    "# Check for missing values in the dataset\n",
    "missing_data = df.isnull().sum()\n",
    "missing_data\n",
    "\n",
    "# Detect outliers: Values exceeding 3 standard deviations from the mean\n",
    "mean_weight = df['Weight_20by100_cm'].mean()\n",
    "std_weight = df['Weight_20by100_cm'].std()\n",
    "outliers = df[(df['Weight_20by100_cm'] > mean_weight + 3 * std_weight) | \n",
    "              (df['Weight_20by100_cm'] < mean_weight - 3 * std_weight)]\n",
    "\n",
    "outliers\n",
    "```\n",
    "\n",
    "### 5. **Backend Validation with Frictionless for IT Staff**\n",
    "\n",
    "IT staff can use a Python script to validate the data programmatically. This approach allows you to automate the validation of any new datasets uploaded to EnviDat.\n",
    "\n",
    "```python\n",
    "from frictionless import Package\n",
    "\n",
    "# Assume the dataset is saved as 'ecological_data.csv'\n",
    "df.to_csv('ecological_data.csv', index=False)\n",
    "\n",
    "# Create a package that includes the dataset and schema for validation\n",
    "package = Package(resources=[{\n",
    "    'name': 'ecological_data',\n",
    "    'path': 'ecological_data.csv',\n",
    "    'schema': schema\n",
    "}])\n",
    "\n",
    "# Validate the package\n",
    "package.validate()\n",
    "\n",
    "# Check for validation issues (if any)\n",
    "if package.valid:\n",
    "    print(\"Data passed validation\")\n",
    "else:\n",
    "    print(\"Data failed validation:\", package.errors)\n",
    "```\n",
    "\n",
    "### 6. **Handling Missing Data and Outliers**\n",
    "\n",
    "Hereâ€™s how to handle missing data and outliers before uploading the data to EnviDat. Researchers can manually fill in missing values or use imputation methods.\n",
    "\n",
    "#### Handling Missing Data:\n",
    "\n",
    "```python\n",
    "# Filling missing values with a placeholder (e.g., 0 or the column mean)\n",
    "df['Weight_20by100_cm'].fillna(df['Weight_20by100_cm'].mean(), inplace=True)\n",
    "\n",
    "# Verify that missing data has been handled\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "#### Handling Outliers:\n",
    "\n",
    "```python\n",
    "# Handling outliers by replacing them with a threshold value (e.g., the 99th percentile)\n",
    "threshold = df['Weight_20by100_cm'].quantile(0.99)\n",
    "df['Weight_20by100_cm'] = df['Weight_20by100_cm'].apply(lambda x: min(x, threshold))\n",
    "\n",
    "# Verify outliers are handled\n",
    "df['Weight_20by100_cm'].describe()\n",
    "```\n",
    "\n",
    "### 7. **Visualizing Data Issues**\n",
    "\n",
    "Visualizing missing data and outliers can help researchers better understand data quality issues.\n",
    "\n",
    "#### Visualizing Missing Data:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Heatmap for missing data\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='Blues')\n",
    "plt.title('Missing Data Heatmap')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Visualizing Outliers:\n",
    "\n",
    "```python\n",
    "# Boxplot for detecting outliers in the 'Weight_20by100_cm' column\n",
    "sns.boxplot(x=df['Weight_20by100_cm'])\n",
    "plt.title('Outliers in Weight_20by100_cm')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 8. **Conclusion: Quality Assurance and Control for Ecological Datasets**\n",
    "\n",
    "By using Frictionless, both researchers and IT staff at WSL can:\n",
    "\n",
    "* **Self-check** their datasets before uploading to EnviDat using the Open Data Editor (GUI).\n",
    "* **Automate backend validation** to ensure uploaded datasets meet the required quality standards.\n",
    "\n",
    "This framework will help identify common issues like missing values, outliers, and data type mismatches early, ensuring the integrity and consistency of ecological data shared in EnviDat.\n",
    "\n",
    "For more detailed examples and information:\n",
    "\n",
    "* [Frictionless Framework Documentation](https://framework.frictionlessdata.io/index.html)\n",
    "* [Frictionless RDM Workflows (Colab)](https://colab.research.google.com/github/frictionlessdata/frictionless-py/blob/v4/site/docs/tutorials/notebooks/frictionless-RDM-workflows.ipynb#scrollTo=dc538394)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe6dc0-4ab7-482c-841c-fdfb29c7c0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
